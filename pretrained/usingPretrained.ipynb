{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from src.dogFunctions import *\n",
    "from src.imageTrans import plotGrid\n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, ELU, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses( history ):\n",
    "    \"\"\"Plots training/validation loss as a fucntion of epoch.\"\"\"\n",
    "\n",
    "    fig = plt.figure( figsize = (18,10) )\n",
    "    plt.plot( range(1, len(history[\"loss\"]) + 1), history[\"loss\"], \"b-\",\n",
    "              linewidth = 3, label = \"$\\mathrm{training}$\")\n",
    "    plt.plot( range(1, len(history[\"val_loss\"]) + 1), history[\"val_loss\"], \"g-\",\n",
    "              linewidth = 3, label = \"$\\mathrm{validation}$\")\n",
    "    plt.ylabel(\"$\\mathrm{Loss}$\")\n",
    "    plt.xlabel(\"$\\mathrm{Epoch}$\")\n",
    "    plt.legend( loc = \"best\" )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def plotAcc( history ):\n",
    "    \"\"\"Plots training/validation accuracy as a fucntion of epoch.\"\"\"\n",
    "\n",
    "    fig = plt.figure( figsize = (18,10) )\n",
    "    plt.plot( range(1, len(history[\"acc\"]) + 1), history[\"acc\"], \"b-\",\n",
    "              linewidth = 3, label = \"$\\mathrm{training}$\")\n",
    "    plt.plot( range(1, len(history[\"val_acc\"]) + 1), history[\"val_acc\"], \"g-\",\n",
    "              linewidth = 3, label = \"$\\mathrm{validation}$\")\n",
    "    plt.ylabel(\"$\\mathrm{Accuracy}$\")\n",
    "    plt.xlabel(\"$\\mathrm{Epoch}$\")\n",
    "    plt.legend( loc = \"best\" )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def accurracy(X, y):\n",
    "    \n",
    "    preds = np.argmax( model.predict( X ), axis = 1 )\n",
    "    y = np.argmax( y, axis = 1 )\n",
    "    \n",
    "    return np.sum( preds == y ) / len(y)\n",
    "\n",
    "def denseBlock( x, size, dropout ):\n",
    "    \"\"\"Createsn one dense layer unit.\"\"\"\n",
    "\n",
    "    dense      = Dense( size, use_bias = False, activation = \"elu\" )( x )\n",
    "    bn         = ELU()( BatchNormalization()(dense) )\n",
    "    dropout    = Dropout( dropout )( bn )\n",
    "    \n",
    "    return dropout\n",
    "\n",
    "def genModel( imgSize = 256, dropout = 0.5 ):\n",
    "    \"\"\"Generates the VAE model.\"\"\"\n",
    "\n",
    "    pretrained = InceptionResNetV2( input_shape = (imgSize, imgSize, 3), weights = 'imagenet',\n",
    "                                    include_top = False )#, pooling = \"avg\" )\n",
    "    inputLayer = pretrained.output\n",
    "\n",
    "    flat = Flatten()( inputLayer )\n",
    "\n",
    "    dense1 = denseBlock( flat,   1024, dropout )\n",
    "    dense2 = denseBlock( dense1, 1024, dropout )\n",
    "    dense3 = denseBlock( dense2, 1024,  dropout )\n",
    "    dense4 = denseBlock( dense3, 1024, dropout )\n",
    "    dense5 = denseBlock( dense4, 1024, dropout )\n",
    "\n",
    "    outputLayer = Dense( 120, activation = \"softmax\" )( dense5 )\n",
    "\n",
    "    for layer in pretrained.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    opt = Adam() #Adam( lr = 0.1, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1.0 )\n",
    "\n",
    "    model = Model( inputs = pretrained.input, outputs = outputLayer )\n",
    "    model.compile( optimizer = opt, loss = \"categorical_crossentropy\", metrics = [ 'acc' ] )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFresh = False\n",
    "\n",
    "breeds = readBreeds()\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "labels['breed'] = pd.Categorical( labels['breed'], categories = breeds )\n",
    "labels['breed'] = labels['breed'].cat.codes\n",
    "    \n",
    "if ( trainFresh ):\n",
    "\n",
    "    trainFiles = np.array( glob('./trainCrop/*.jpg') )\n",
    "    \n",
    "    valFiles = sampleDogs( trainFiles, labels, 0.147 )\n",
    "    valFiles = np.array( list(set(valFiles)) )\n",
    "\n",
    "    tmp = []\n",
    "    \n",
    "    for f in trainFiles:\n",
    "        if ( not (f in valFiles) ):\n",
    "            tmp.append(f)\n",
    "            \n",
    "    trainFiles = np.array( tmp )\n",
    "    np.random.shuffle(trainFiles)\n",
    "\n",
    "    writeFilesList( \"trainFiles.txt\", trainFiles )\n",
    "    writeFilesList( \"valFiles.txt\", valFiles )\n",
    "\n",
    "else:\n",
    "    valFiles   = readSavedFiles( \"valFiles.txt\" )\n",
    "    trainFiles = readSavedFiles( \"trainFiles.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 127, 127, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 127, 127, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 125, 125, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 125, 125, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 125, 125, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 62, 62, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 62, 62, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 60, 60, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 29, 29, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 29, 29, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 29, 29, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 29, 29, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 29, 29, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 29, 29, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 29, 29, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 29, 29, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 29, 29, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 29, 29, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 29, 29, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 29, 29, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 29, 29, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 29, 29, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 29, 29, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 29, 29, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 29, 29, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 29, 29, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 29, 29, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 29, 29, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 29, 29, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 29, 29, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 29, 29, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 29, 29, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 29, 29, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 29, 29, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 29, 29, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 29, 29, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 29, 29, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 29, 29, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 29, 29, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 29, 29, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 29, 29, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 29, 29, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 29, 29, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 29, 29, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 29, 29, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 29, 29, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 29, 29, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 29, 29, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 29, 29, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 29, 29, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 29, 29, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 29, 29, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 29, 29, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 29, 29, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 29, 29, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 29, 29, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 29, 29, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 29, 29, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 29, 29, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 29, 29, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 29, 29, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 29, 29, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 29, 29, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 29, 29, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 29, 29, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 29, 29, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 29, 29, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 29, 29, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 29, 29, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 29, 29, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 29, 29, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 29, 29, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 29, 29, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 29, 29, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 29, 29, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 29, 29, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 29, 29, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 29, 29, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 29, 29, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 29, 29, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 29, 29, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 29, 29, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 29, 29, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 29, 29, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 29, 29, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 29, 29, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 29, 29, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 29, 29, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 29, 29, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 29, 29, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 29, 29, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 29, 29, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 29, 29, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 29, 29, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 29, 29, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 29, 29, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 29, 29, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 29, 29, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 29, 29, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 29, 29, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 29, 29, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 29, 29, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 29, 29, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 29, 29, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 29, 29, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 29, 29, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 29, 29, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 29, 29, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 29, 29, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 29, 29, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 29, 29, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 29, 29, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 29, 29, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 29, 29, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 29, 29, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 29, 29, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 29, 29, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 29, 29, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 29, 29, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 29, 29, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 29, 29, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 29, 29, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 29, 29, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 29, 29, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 29, 29, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 29, 29, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 29, 29, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 29, 29, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 29, 29, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 29, 29, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 29, 29, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 29, 29, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 29, 29, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 29, 29, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 29, 29, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 29, 29, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 29, 29, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 29, 29, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 29, 29, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 29, 29, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 29, 29, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 29, 29, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 29, 29, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 29, 29, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 29, 29, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 29, 29, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 29, 29, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 29, 29, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 29, 29, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 29, 29, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 14, 14, 384)  884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 14, 14, 384)  1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 14, 14, 1088) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 160)  143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 160)  480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 192)  215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 14, 14, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 14, 14, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 160)  143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 160)  480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 192)  215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 14, 14, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 14, 14, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 128)  384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 160)  143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 160)  480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 192)  215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 14, 14, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 14, 14, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 128)  384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 14, 14, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 160)  143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 160)  480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 14, 14, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 192)  215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 14, 14, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 14, 14, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 14, 14, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 14, 14, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 160)  143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 160)  480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 14, 14, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 192)  215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 14, 14, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 14, 14, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 14, 14, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 14, 14, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 14, 14, 128)  384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 14, 14, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 160)  143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 14, 14, 160)  480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 14, 14, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 192)  215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 14, 14, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 14, 14, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 14, 14, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 14, 14, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 14, 14, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 14, 14, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 14, 14, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 14, 14, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 160)  143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 14, 14, 160)  480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 14, 14, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 192)  215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 14, 14, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 14, 14, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 14, 14, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 14, 14, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 14, 14, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 14, 14, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 14, 14, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 14, 14, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 160)  143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 14, 14, 160)  480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 14, 14, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 192)  215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 14, 14, 192)  576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 14, 14, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 14, 14, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 14, 14, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 14, 14, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 14, 14, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 14, 14, 128)  384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 14, 14, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 160)  143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 14, 14, 160)  480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 14, 14, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 192)  215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 14, 14, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 14, 14, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 14, 14, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 14, 14, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 14, 14, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 14, 14, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 14, 14, 128)  384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 14, 14, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 160)  143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 14, 14, 160)  480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 14, 14, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 192)  215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 14, 14, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 14, 14, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 14, 14, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 14, 14, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 14, 14, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 14, 14, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 14, 14, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 14, 14, 128)  384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 14, 14, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 14, 14, 160)  143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 14, 14, 160)  480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 14, 14, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 14, 14, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 14, 14, 192)  215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 14, 14, 192)  576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 14, 14, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 14, 14, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 14, 14, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 14, 14, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 14, 14, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 14, 14, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 14, 14, 128)  384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 14, 14, 160)  143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 14, 14, 160)  480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 14, 14, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 14, 14, 192)  215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 14, 14, 192)  576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 14, 14, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 14, 14, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 14, 14, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 14, 14, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 14, 14, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 14, 14, 160)  143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 14, 14, 160)  480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 14, 14, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 14, 14, 192)  215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 14, 14, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 14, 14, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 14, 14, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 14, 14, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 14, 14, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 14, 14, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 14, 14, 160)  143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 14, 14, 160)  480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 14, 14, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 14, 14, 192)  215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 14, 14, 192)  576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 14, 14, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 14, 14, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 14, 14, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 14, 14, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 14, 14, 128)  384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 14, 14, 160)  143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 14, 14, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 14, 14, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 14, 14, 192)  215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 14, 14, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 14, 14, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 14, 14, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 14, 14, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 14, 14, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 14, 14, 128)  384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 14, 14, 160)  143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 14, 14, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 14, 14, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 14, 14, 192)  215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 14, 14, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 14, 14, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 14, 14, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 14, 14, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 14, 14, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 14, 14, 128)  384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 14, 14, 160)  143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 14, 14, 160)  480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 14, 14, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 14, 14, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 14, 14, 192)  576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 14, 14, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 14, 14, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 14, 14, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 14, 14, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 14, 14, 128)  384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 14, 14, 160)  143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 14, 14, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 14, 14, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 14, 14, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 14, 14, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 14, 14, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 14, 14, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 14, 14, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 14, 14, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 14, 14, 128)  384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 14, 14, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 14, 14, 160)  143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 14, 14, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 14, 14, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 14, 14, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 14, 14, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 14, 14, 192)  576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 14, 14, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 14, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 14, 14, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 14, 14, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 14, 14, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 14, 14, 128)  384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 14, 14, 160)  143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 14, 14, 160)  480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 160)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 14, 14, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 14, 14, 192)  215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 14, 14, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 14, 14, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 14, 14, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 14, 14, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 14, 14, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 14, 14, 256)  768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 14, 14, 288)  663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 14, 14, 256)  768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 14, 14, 256)  768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 14, 14, 288)  864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 6, 6, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 6, 6, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 6, 6, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 6, 6, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 6, 6, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 6, 6, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 6, 6, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 6, 6, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 6, 6, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 6, 6, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 6, 6, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 6, 6, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 6, 6, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 6, 6, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 6, 6, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 6, 6, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 6, 6, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 6, 6, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 6, 6, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 6, 6, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 6, 6, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 6, 6, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 6, 6, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 6, 6, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 6, 6, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 6, 6, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 6, 6, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 6, 6, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 6, 6, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 6, 6, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 6, 6, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 6, 6, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 6, 6, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 6, 6, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 6, 6, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 6, 6, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 6, 6, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 6, 6, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 6, 6, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 6, 6, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 6, 6, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 6, 6, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 6, 6, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 6, 6, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 6, 6, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 6, 6, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 6, 6, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 6, 6, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 6, 6, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 6, 6, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 6, 6, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 6, 6, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 6, 6, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 6, 6, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 6, 6, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 6, 6, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 6, 6, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 6, 6, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 6, 6, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 6, 6, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 6, 6, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 6, 6, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 6, 6, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 6, 6, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 6, 6, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 6, 6, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 6, 6, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 6, 6, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 6, 6, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 6, 6, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 6, 6, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 6, 6, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 6, 6, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 6, 6, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 6, 6, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 6, 6, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 6, 6, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 6, 6, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 6, 6, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 6, 6, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 6, 6, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 6, 6, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 6, 6, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 6, 6, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 6, 6, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 6, 6, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 6, 6, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 6, 6, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 6, 6, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 6, 6, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 6, 6, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 6, 6, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 6, 6, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 6, 6, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 6, 6, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 6, 6, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 6, 6, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 6, 6, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 6, 6, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 6, 6, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 6, 6, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 6, 6, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 6, 6, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 6, 6, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 6, 6, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 6, 6, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 6, 6, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 6, 6, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 6, 6, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 6, 6, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 6, 6, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 6, 6, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 6, 6, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 6, 6, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 6, 6, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 6, 6, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 6, 6, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 6, 6, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 6, 6, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 6, 6, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 6, 6, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 6, 6, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 6, 6, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 6, 6, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 6, 6, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 6, 6, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 6, 6, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 6, 6, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 6, 6, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 6, 6, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 6, 6, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 6, 6, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 55296)        0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         56623104    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 1024)         0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1048576     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 1024)         4096        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 1024)         0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1048576     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 1024)         4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 1024)         0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1048576     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 1024)         4096        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 1024)         0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         1048576     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 1024)         4096        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 1024)         0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          123000      dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 115,297,624\n",
      "Trainable params: 60,950,648\n",
      "Non-trainable params: 54,346,976\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imgSize = 256\n",
    "dropout = 0.75\n",
    "\n",
    "model = genModel( imgSize, dropout )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 6.9533 - acc: 0.0103\n",
      "Epoch 00001: val_loss improved from inf to 4.54916, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 157s 1s/step - loss: 6.9490 - acc: 0.0104 - val_loss: 4.5492 - val_acc: 0.0334\n",
      "Epoch 2/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 6.2723 - acc: 0.0125\n",
      "Epoch 00002: val_loss improved from 4.54916 to 4.00917, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 100s 733ms/step - loss: 6.2713 - acc: 0.0125 - val_loss: 4.0092 - val_acc: 0.1341\n",
      "Epoch 3/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 5.4650 - acc: 0.0353\n",
      "Epoch 00003: val_loss improved from 4.00917 to 3.20645, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 109s 798ms/step - loss: 5.4623 - acc: 0.0356 - val_loss: 3.2065 - val_acc: 0.2123\n",
      "Epoch 4/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 4.6037 - acc: 0.0619\n",
      "Epoch 00004: val_loss improved from 3.20645 to 2.38315, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 106s 777ms/step - loss: 4.6033 - acc: 0.0619 - val_loss: 2.3832 - val_acc: 0.3717\n",
      "Epoch 5/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 4.0158 - acc: 0.0991\n",
      "Epoch 00005: val_loss improved from 2.38315 to 1.98169, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 105s 764ms/step - loss: 4.0158 - acc: 0.0988 - val_loss: 1.9817 - val_acc: 0.4565\n",
      "Epoch 6/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 3.5525 - acc: 0.1490\n",
      "Epoch 00006: val_loss improved from 1.98169 to 1.73188, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 105s 769ms/step - loss: 3.5524 - acc: 0.1486 - val_loss: 1.7319 - val_acc: 0.5014\n",
      "Epoch 7/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 3.2598 - acc: 0.1867\n",
      "Epoch 00007: val_loss improved from 1.73188 to 1.46962, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 3.2570 - acc: 0.1869 - val_loss: 1.4696 - val_acc: 0.5565\n",
      "Epoch 8/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.9923 - acc: 0.2319\n",
      "Epoch 00008: val_loss improved from 1.46962 to 1.25317, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 748ms/step - loss: 2.9937 - acc: 0.2320 - val_loss: 1.2532 - val_acc: 0.6174\n",
      "Epoch 9/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.7058 - acc: 0.2811\n",
      "Epoch 00009: val_loss improved from 1.25317 to 1.01913, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 741ms/step - loss: 2.7026 - acc: 0.2814 - val_loss: 1.0191 - val_acc: 0.6920\n",
      "Epoch 10/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.5945 - acc: 0.3041\n",
      "Epoch 00010: val_loss did not improve\n",
      "137/137 [==============================] - 102s 743ms/step - loss: 2.5928 - acc: 0.3053 - val_loss: 1.0691 - val_acc: 0.7319\n",
      "Epoch 11/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.4087 - acc: 0.3443\n",
      "Epoch 00011: val_loss improved from 1.01913 to 0.88516, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 107s 785ms/step - loss: 2.4079 - acc: 0.3443 - val_loss: 0.8852 - val_acc: 0.7406\n",
      "Epoch 12/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.3714 - acc: 0.3631\n",
      "Epoch 00012: val_loss improved from 0.88516 to 0.84744, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 103s 748ms/step - loss: 2.3719 - acc: 0.3629 - val_loss: 0.8474 - val_acc: 0.7652\n",
      "Epoch 13/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.2306 - acc: 0.4001\n",
      "Epoch 00013: val_loss improved from 0.84744 to 0.77151, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 741ms/step - loss: 2.2332 - acc: 0.3997 - val_loss: 0.7715 - val_acc: 0.7681\n",
      "Epoch 14/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.1600 - acc: 0.4186\n",
      "Epoch 00014: val_loss improved from 0.77151 to 0.71755, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 745ms/step - loss: 2.1646 - acc: 0.4178 - val_loss: 0.7175 - val_acc: 0.7971\n",
      "Epoch 15/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.0782 - acc: 0.4388\n",
      "Epoch 00015: val_loss did not improve\n",
      "137/137 [==============================] - 97s 709ms/step - loss: 2.0751 - acc: 0.4391 - val_loss: 0.7444 - val_acc: 0.7964\n",
      "Epoch 16/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.0298 - acc: 0.4509\n",
      "Epoch 00016: val_loss improved from 0.71755 to 0.64261, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 101s 738ms/step - loss: 2.0246 - acc: 0.4519 - val_loss: 0.6426 - val_acc: 0.8123\n",
      "Epoch 17/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.9926 - acc: 0.4597\n",
      "Epoch 00017: val_loss improved from 0.64261 to 0.63513, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 103s 751ms/step - loss: 1.9941 - acc: 0.4597 - val_loss: 0.6351 - val_acc: 0.8225\n",
      "Epoch 18/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 2.0098 - acc: 0.4650\n",
      "Epoch 00018: val_loss improved from 0.63513 to 0.62899, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 743ms/step - loss: 2.0059 - acc: 0.4657 - val_loss: 0.6290 - val_acc: 0.8196\n",
      "Epoch 19/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.9392 - acc: 0.4753\n",
      "Epoch 00019: val_loss improved from 0.62899 to 0.59394, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 105s 766ms/step - loss: 1.9389 - acc: 0.4750 - val_loss: 0.5939 - val_acc: 0.8362\n",
      "Epoch 20/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.8812 - acc: 0.4897\n",
      "Epoch 00020: val_loss did not improve\n",
      "137/137 [==============================] - 103s 748ms/step - loss: 1.8787 - acc: 0.4900 - val_loss: 0.6044 - val_acc: 0.8239\n",
      "Epoch 21/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.7786 - acc: 0.5132\n",
      "Epoch 00021: val_loss did not improve\n",
      "137/137 [==============================] - 99s 721ms/step - loss: 1.7773 - acc: 0.5131 - val_loss: 0.6086 - val_acc: 0.8319\n",
      "Epoch 22/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.7649 - acc: 0.5211\n",
      "Epoch 00022: val_loss improved from 0.59394 to 0.56184, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 102s 744ms/step - loss: 1.7653 - acc: 0.5213 - val_loss: 0.5618 - val_acc: 0.8551\n",
      "Epoch 23/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6909 - acc: 0.5209\n",
      "Epoch 00023: val_loss did not improve\n",
      "137/137 [==============================] - 100s 729ms/step - loss: 1.6909 - acc: 0.5215 - val_loss: 0.5864 - val_acc: 0.8348\n",
      "Epoch 24/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6946 - acc: 0.5320\n",
      "Epoch 00024: val_loss improved from 0.56184 to 0.54557, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 98s 719ms/step - loss: 1.6929 - acc: 0.5324 - val_loss: 0.5456 - val_acc: 0.8530\n",
      "Epoch 25/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6705 - acc: 0.5417\n",
      "Epoch 00025: val_loss did not improve\n",
      "137/137 [==============================] - 99s 723ms/step - loss: 1.6746 - acc: 0.5412 - val_loss: 0.5822 - val_acc: 0.8406\n",
      "Epoch 26/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6528 - acc: 0.5438\n",
      "Epoch 00026: val_loss did not improve\n",
      "137/137 [==============================] - 99s 722ms/step - loss: 1.6508 - acc: 0.5442 - val_loss: 0.5793 - val_acc: 0.8493\n",
      "Epoch 27/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.7053 - acc: 0.5407\n",
      "Epoch 00027: val_loss improved from 0.54557 to 0.52763, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 98s 716ms/step - loss: 1.7043 - acc: 0.5407 - val_loss: 0.5276 - val_acc: 0.8551\n",
      "Epoch 28/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.7040 - acc: 0.5402\n",
      "Epoch 00028: val_loss did not improve\n",
      "137/137 [==============================] - 100s 730ms/step - loss: 1.7036 - acc: 0.5405 - val_loss: 0.5463 - val_acc: 0.8522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6629 - acc: 0.5537\n",
      "Epoch 00029: val_loss did not improve\n",
      "137/137 [==============================] - 101s 736ms/step - loss: 1.6651 - acc: 0.5532 - val_loss: 0.5525 - val_acc: 0.8493\n",
      "Epoch 30/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.6227 - acc: 0.5609\n",
      "Epoch 00030: val_loss did not improve\n",
      "137/137 [==============================] - 97s 709ms/step - loss: 1.6197 - acc: 0.5615 - val_loss: 0.5411 - val_acc: 0.8558\n",
      "Epoch 31/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5315 - acc: 0.5759\n",
      "Epoch 00031: val_loss did not improve\n",
      "137/137 [==============================] - 99s 724ms/step - loss: 1.5319 - acc: 0.5757 - val_loss: 0.5412 - val_acc: 0.8601\n",
      "Epoch 32/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5394 - acc: 0.5696\n",
      "Epoch 00032: val_loss did not improve\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 1.5378 - acc: 0.5701 - val_loss: 0.5308 - val_acc: 0.8500\n",
      "Epoch 33/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5101 - acc: 0.5773\n",
      "Epoch 00033: val_loss did not improve\n",
      "137/137 [==============================] - 103s 751ms/step - loss: 1.5141 - acc: 0.5770 - val_loss: 0.5385 - val_acc: 0.8471\n",
      "Epoch 34/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5744 - acc: 0.5725\n",
      "Epoch 00034: val_loss improved from 0.52763 to 0.51913, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 105s 766ms/step - loss: 1.5829 - acc: 0.5707 - val_loss: 0.5191 - val_acc: 0.8609\n",
      "Epoch 35/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5333 - acc: 0.5781\n",
      "Epoch 00035: val_loss improved from 0.51913 to 0.49560, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 105s 768ms/step - loss: 1.5350 - acc: 0.5775 - val_loss: 0.4956 - val_acc: 0.8659\n",
      "Epoch 36/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5173 - acc: 0.5857\n",
      "Epoch 00036: val_loss did not improve\n",
      "137/137 [==============================] - 100s 726ms/step - loss: 1.5231 - acc: 0.5850 - val_loss: 0.5683 - val_acc: 0.8493\n",
      "Epoch 37/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4829 - acc: 0.5929\n",
      "Epoch 00037: val_loss did not improve\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 1.4877 - acc: 0.5919 - val_loss: 0.5318 - val_acc: 0.8580\n",
      "Epoch 38/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4511 - acc: 0.6051\n",
      "Epoch 00038: val_loss improved from 0.49560 to 0.47992, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 99s 723ms/step - loss: 1.4504 - acc: 0.6057 - val_loss: 0.4799 - val_acc: 0.8710\n",
      "Epoch 39/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.5624 - acc: 0.5842\n",
      "Epoch 00039: val_loss did not improve\n",
      "137/137 [==============================] - 100s 731ms/step - loss: 1.5615 - acc: 0.5839 - val_loss: 0.5372 - val_acc: 0.8551\n",
      "Epoch 40/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4678 - acc: 0.5981\n",
      "Epoch 00040: val_loss did not improve\n",
      "137/137 [==============================] - 101s 736ms/step - loss: 1.4684 - acc: 0.5979 - val_loss: 0.4907 - val_acc: 0.8601\n",
      "Epoch 41/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3883 - acc: 0.6142\n",
      "Epoch 00041: val_loss did not improve\n",
      "137/137 [==============================] - 101s 737ms/step - loss: 1.3905 - acc: 0.6134 - val_loss: 0.4852 - val_acc: 0.8558\n",
      "Epoch 42/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4748 - acc: 0.5983\n",
      "Epoch 00042: val_loss did not improve\n",
      "137/137 [==============================] - 100s 732ms/step - loss: 1.4703 - acc: 0.5988 - val_loss: 0.5143 - val_acc: 0.8623\n",
      "Epoch 43/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3871 - acc: 0.6165\n",
      "Epoch 00043: val_loss did not improve\n",
      "137/137 [==============================] - 104s 761ms/step - loss: 1.3929 - acc: 0.6156 - val_loss: 0.5208 - val_acc: 0.8623\n",
      "Epoch 44/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3827 - acc: 0.6200\n",
      "Epoch 00044: val_loss did not improve\n",
      "137/137 [==============================] - 100s 733ms/step - loss: 1.3808 - acc: 0.6204 - val_loss: 0.5141 - val_acc: 0.8645\n",
      "Epoch 45/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4710 - acc: 0.6045\n",
      "Epoch 00045: val_loss did not improve\n",
      "137/137 [==============================] - 99s 726ms/step - loss: 1.4682 - acc: 0.6048 - val_loss: 0.5010 - val_acc: 0.8514\n",
      "Epoch 46/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3895 - acc: 0.6232\n",
      "Epoch 00046: val_loss did not improve\n",
      "137/137 [==============================] - 99s 725ms/step - loss: 1.3915 - acc: 0.6226 - val_loss: 0.5116 - val_acc: 0.8623\n",
      "Epoch 47/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4291 - acc: 0.6070\n",
      "Epoch 00047: val_loss did not improve\n",
      "137/137 [==============================] - 101s 734ms/step - loss: 1.4255 - acc: 0.6083 - val_loss: 0.5105 - val_acc: 0.8601\n",
      "Epoch 48/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3089 - acc: 0.6358\n",
      "Epoch 00048: val_loss did not improve\n",
      "137/137 [==============================] - 98s 718ms/step - loss: 1.3099 - acc: 0.6358 - val_loss: 0.4975 - val_acc: 0.8659\n",
      "Epoch 49/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.4436 - acc: 0.6173\n",
      "Epoch 00049: val_loss did not improve\n",
      "137/137 [==============================] - 100s 728ms/step - loss: 1.4456 - acc: 0.6167 - val_loss: 0.5148 - val_acc: 0.8514\n",
      "Epoch 50/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3740 - acc: 0.6195\n",
      "Epoch 00050: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 1.3716 - acc: 0.6200 - val_loss: 0.5220 - val_acc: 0.8623\n",
      "Epoch 51/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2712 - acc: 0.6426\n",
      "Epoch 00051: val_loss did not improve\n",
      "137/137 [==============================] - 96s 700ms/step - loss: 1.2691 - acc: 0.6434 - val_loss: 0.4973 - val_acc: 0.8681\n",
      "Epoch 52/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2895 - acc: 0.6460\n",
      "Epoch 00052: val_loss did not improve\n",
      "137/137 [==============================] - 100s 727ms/step - loss: 1.2864 - acc: 0.6462 - val_loss: 0.5086 - val_acc: 0.8638\n",
      "Epoch 53/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2395 - acc: 0.6564\n",
      "Epoch 00053: val_loss did not improve\n",
      "137/137 [==============================] - 94s 687ms/step - loss: 1.2383 - acc: 0.6568 - val_loss: 0.5108 - val_acc: 0.8623\n",
      "Epoch 54/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2947 - acc: 0.6448\n",
      "Epoch 00054: val_loss did not improve\n",
      "137/137 [==============================] - 101s 738ms/step - loss: 1.2925 - acc: 0.6457 - val_loss: 0.4927 - val_acc: 0.8710\n",
      "Epoch 55/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2936 - acc: 0.6426\n",
      "Epoch 00055: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 1.2922 - acc: 0.6426 - val_loss: 0.4992 - val_acc: 0.8681\n",
      "Epoch 56/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3038 - acc: 0.6426\n",
      "Epoch 00056: val_loss did not improve\n",
      "137/137 [==============================] - 101s 738ms/step - loss: 1.3065 - acc: 0.6421 - val_loss: 0.5194 - val_acc: 0.8587\n",
      "Epoch 57/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3737 - acc: 0.6368\n",
      "Epoch 00057: val_loss did not improve\n",
      "137/137 [==============================] - 103s 752ms/step - loss: 1.3798 - acc: 0.6357 - val_loss: 0.4985 - val_acc: 0.8652\n",
      "Epoch 58/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2543 - acc: 0.6468\n",
      "Epoch 00058: val_loss did not improve\n",
      "137/137 [==============================] - 101s 739ms/step - loss: 1.2577 - acc: 0.6461 - val_loss: 0.5029 - val_acc: 0.8645\n",
      "Epoch 59/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3083 - acc: 0.6444\n",
      "Epoch 00059: val_loss did not improve\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 1.3063 - acc: 0.6450 - val_loss: 0.5035 - val_acc: 0.8681\n",
      "Epoch 60/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/137 [============================>.] - ETA: 0s - loss: 1.3166 - acc: 0.6411\n",
      "Epoch 00060: val_loss did not improve\n",
      "137/137 [==============================] - 101s 738ms/step - loss: 1.3227 - acc: 0.6397 - val_loss: 0.5238 - val_acc: 0.8630\n",
      "Epoch 61/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2939 - acc: 0.6447\n",
      "Epoch 00061: val_loss improved from 0.47992 to 0.40948, saving model to ./best/dogClass.hdf5\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 1.2929 - acc: 0.6443 - val_loss: 0.4095 - val_acc: 0.8826\n",
      "Epoch 62/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2897 - acc: 0.6440\n",
      "Epoch 00062: val_loss did not improve\n",
      "137/137 [==============================] - 99s 721ms/step - loss: 1.2865 - acc: 0.6447 - val_loss: 0.5104 - val_acc: 0.8761\n",
      "Epoch 63/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3022 - acc: 0.6372\n",
      "Epoch 00063: val_loss did not improve\n",
      "137/137 [==============================] - 97s 707ms/step - loss: 1.3007 - acc: 0.6376 - val_loss: 0.4777 - val_acc: 0.8761\n",
      "Epoch 64/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.3131 - acc: 0.6451\n",
      "Epoch 00064: val_loss did not improve\n",
      "137/137 [==============================] - 100s 727ms/step - loss: 1.3107 - acc: 0.6455 - val_loss: 0.4611 - val_acc: 0.8703\n",
      "Epoch 65/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2697 - acc: 0.6475\n",
      "Epoch 00065: val_loss did not improve\n",
      "137/137 [==============================] - 98s 717ms/step - loss: 1.2685 - acc: 0.6477 - val_loss: 0.5010 - val_acc: 0.8696\n",
      "Epoch 66/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1703 - acc: 0.6685\n",
      "Epoch 00066: val_loss did not improve\n",
      "137/137 [==============================] - 98s 717ms/step - loss: 1.1695 - acc: 0.6680 - val_loss: 0.4836 - val_acc: 0.8717\n",
      "Epoch 67/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2839 - acc: 0.6477\n",
      "Epoch 00067: val_loss did not improve\n",
      "137/137 [==============================] - 100s 730ms/step - loss: 1.2868 - acc: 0.6476 - val_loss: 0.5134 - val_acc: 0.8696\n",
      "Epoch 68/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2865 - acc: 0.6537\n",
      "Epoch 00068: val_loss did not improve\n",
      "137/137 [==============================] - 103s 750ms/step - loss: 1.2842 - acc: 0.6539 - val_loss: 0.4807 - val_acc: 0.8746\n",
      "Epoch 69/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2550 - acc: 0.6572\n",
      "Epoch 00069: val_loss did not improve\n",
      "137/137 [==============================] - 104s 762ms/step - loss: 1.2533 - acc: 0.6581 - val_loss: 0.4709 - val_acc: 0.8688\n",
      "Epoch 70/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1842 - acc: 0.6651\n",
      "Epoch 00070: val_loss did not improve\n",
      "137/137 [==============================] - 100s 729ms/step - loss: 1.1857 - acc: 0.6647 - val_loss: 0.4921 - val_acc: 0.8743\n",
      "Epoch 71/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2032 - acc: 0.6687\n",
      "Epoch 00071: val_loss did not improve\n",
      "137/137 [==============================] - 105s 770ms/step - loss: 1.2012 - acc: 0.6696 - val_loss: 0.4897 - val_acc: 0.8754\n",
      "Epoch 72/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2351 - acc: 0.6613\n",
      "Epoch 00072: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 1.2404 - acc: 0.6600 - val_loss: 0.4919 - val_acc: 0.8717\n",
      "Epoch 73/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1543 - acc: 0.6780\n",
      "Epoch 00073: val_loss did not improve\n",
      "137/137 [==============================] - 97s 705ms/step - loss: 1.1531 - acc: 0.6777 - val_loss: 0.4751 - val_acc: 0.8710\n",
      "Epoch 74/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2072 - acc: 0.6708\n",
      "Epoch 00074: val_loss did not improve\n",
      "137/137 [==============================] - 99s 719ms/step - loss: 1.2041 - acc: 0.6712 - val_loss: 0.5147 - val_acc: 0.8725\n",
      "Epoch 75/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2104 - acc: 0.6690\n",
      "Epoch 00075: val_loss did not improve\n",
      "137/137 [==============================] - 107s 778ms/step - loss: 1.2119 - acc: 0.6687 - val_loss: 0.4670 - val_acc: 0.8797\n",
      "Epoch 76/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1666 - acc: 0.6744\n",
      "Epoch 00076: val_loss did not improve\n",
      "137/137 [==============================] - 105s 764ms/step - loss: 1.1681 - acc: 0.6739 - val_loss: 0.5187 - val_acc: 0.8739\n",
      "Epoch 77/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0999 - acc: 0.6947\n",
      "Epoch 00077: val_loss did not improve\n",
      "137/137 [==============================] - 98s 716ms/step - loss: 1.0989 - acc: 0.6953 - val_loss: 0.4925 - val_acc: 0.8725\n",
      "Epoch 78/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1437 - acc: 0.6731\n",
      "Epoch 00078: val_loss did not improve\n",
      "137/137 [==============================] - 103s 751ms/step - loss: 1.1401 - acc: 0.6742 - val_loss: 0.4418 - val_acc: 0.8732\n",
      "Epoch 79/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1413 - acc: 0.6810\n",
      "Epoch 00079: val_loss did not improve\n",
      "137/137 [==============================] - 102s 744ms/step - loss: 1.1405 - acc: 0.6807 - val_loss: 0.5688 - val_acc: 0.8659\n",
      "Epoch 80/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2406 - acc: 0.6655\n",
      "Epoch 00080: val_loss did not improve\n",
      "137/137 [==============================] - 99s 720ms/step - loss: 1.2396 - acc: 0.6660 - val_loss: 0.4338 - val_acc: 0.8812\n",
      "Epoch 81/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.2514 - acc: 0.6651\n",
      "Epoch 00081: val_loss did not improve\n",
      "137/137 [==============================] - 100s 730ms/step - loss: 1.2479 - acc: 0.6654 - val_loss: 0.5353 - val_acc: 0.8551\n",
      "Epoch 82/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1056 - acc: 0.6902\n",
      "Epoch 00082: val_loss did not improve\n",
      "137/137 [==============================] - 99s 725ms/step - loss: 1.1111 - acc: 0.6889 - val_loss: 0.4823 - val_acc: 0.8768\n",
      "Epoch 83/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1369 - acc: 0.6877\n",
      "Epoch 00083: val_loss did not improve\n",
      "137/137 [==============================] - 99s 723ms/step - loss: 1.1384 - acc: 0.6873 - val_loss: 0.4722 - val_acc: 0.8645\n",
      "Epoch 84/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1663 - acc: 0.6813\n",
      "Epoch 00084: val_loss did not improve\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 1.1647 - acc: 0.6815 - val_loss: 0.5162 - val_acc: 0.8790\n",
      "Epoch 85/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1517 - acc: 0.6868\n",
      "Epoch 00085: val_loss did not improve\n",
      "137/137 [==============================] - 102s 747ms/step - loss: 1.1536 - acc: 0.6867 - val_loss: 0.4176 - val_acc: 0.8725\n",
      "Epoch 86/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0647 - acc: 0.7053\n",
      "Epoch 00086: val_loss did not improve\n",
      "137/137 [==============================] - 104s 760ms/step - loss: 1.0638 - acc: 0.7057 - val_loss: 0.5304 - val_acc: 0.8645\n",
      "Epoch 87/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1657 - acc: 0.6837\n",
      "Epoch 00087: val_loss did not improve\n",
      "137/137 [==============================] - 101s 734ms/step - loss: 1.1660 - acc: 0.6837 - val_loss: 0.4501 - val_acc: 0.8826\n",
      "Epoch 88/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1409 - acc: 0.6898\n",
      "Epoch 00088: val_loss did not improve\n",
      "137/137 [==============================] - 99s 725ms/step - loss: 1.1380 - acc: 0.6906 - val_loss: 0.5034 - val_acc: 0.8717\n",
      "Epoch 89/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0851 - acc: 0.6965\n",
      "Epoch 00089: val_loss did not improve\n",
      "137/137 [==============================] - 101s 735ms/step - loss: 1.0845 - acc: 0.6966 - val_loss: 0.4507 - val_acc: 0.8804\n",
      "Epoch 90/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1087 - acc: 0.6949\n",
      "Epoch 00090: val_loss did not improve\n",
      "137/137 [==============================] - 103s 750ms/step - loss: 1.1082 - acc: 0.6953 - val_loss: 0.4700 - val_acc: 0.8790\n",
      "Epoch 91/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1009 - acc: 0.7036\n",
      "Epoch 00091: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 1.1056 - acc: 0.7025 - val_loss: 0.4732 - val_acc: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0396 - acc: 0.7059\n",
      "Epoch 00092: val_loss did not improve\n",
      "137/137 [==============================] - 102s 741ms/step - loss: 1.0426 - acc: 0.7053 - val_loss: 0.4889 - val_acc: 0.8775\n",
      "Epoch 93/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1471 - acc: 0.6884\n",
      "Epoch 00093: val_loss did not improve\n",
      "137/137 [==============================] - 101s 741ms/step - loss: 1.1452 - acc: 0.6889 - val_loss: 0.4742 - val_acc: 0.8729\n",
      "Epoch 94/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0873 - acc: 0.6993\n",
      "Epoch 00094: val_loss did not improve\n",
      "137/137 [==============================] - 97s 709ms/step - loss: 1.0869 - acc: 0.6995 - val_loss: 0.4839 - val_acc: 0.8797\n",
      "Epoch 95/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0160 - acc: 0.7145\n",
      "Epoch 00095: val_loss did not improve\n",
      "137/137 [==============================] - 101s 738ms/step - loss: 1.0192 - acc: 0.7139 - val_loss: 0.4784 - val_acc: 0.8790\n",
      "Epoch 96/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0898 - acc: 0.6970\n",
      "Epoch 00096: val_loss did not improve\n",
      "137/137 [==============================] - 100s 728ms/step - loss: 1.0882 - acc: 0.6974 - val_loss: 0.4819 - val_acc: 0.8703\n",
      "Epoch 97/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1238 - acc: 0.6884\n",
      "Epoch 00097: val_loss did not improve\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 1.1259 - acc: 0.6880 - val_loss: 0.4769 - val_acc: 0.8717\n",
      "Epoch 98/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0585 - acc: 0.6998\n",
      "Epoch 00098: val_loss did not improve\n",
      "137/137 [==============================] - 102s 744ms/step - loss: 1.0578 - acc: 0.6997 - val_loss: 0.5186 - val_acc: 0.8725\n",
      "Epoch 99/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0635 - acc: 0.7031\n",
      "Epoch 00099: val_loss did not improve\n",
      "137/137 [==============================] - 98s 714ms/step - loss: 1.0700 - acc: 0.7018 - val_loss: 0.5029 - val_acc: 0.8652\n",
      "Epoch 100/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0647 - acc: 0.7106\n",
      "Epoch 00100: val_loss did not improve\n",
      "137/137 [==============================] - 99s 726ms/step - loss: 1.0626 - acc: 0.7111 - val_loss: 0.4401 - val_acc: 0.8841\n",
      "Epoch 101/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0453 - acc: 0.7071\n",
      "Epoch 00101: val_loss did not improve\n",
      "137/137 [==============================] - 100s 732ms/step - loss: 1.0462 - acc: 0.7070 - val_loss: 0.4791 - val_acc: 0.8812\n",
      "Epoch 102/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0635 - acc: 0.7107\n",
      "Epoch 00102: val_loss did not improve\n",
      "137/137 [==============================] - 98s 717ms/step - loss: 1.0596 - acc: 0.7117 - val_loss: 0.5189 - val_acc: 0.8754\n",
      "Epoch 103/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0420 - acc: 0.7144\n",
      "Epoch 00103: val_loss did not improve\n",
      "137/137 [==============================] - 102s 745ms/step - loss: 1.0499 - acc: 0.7125 - val_loss: 0.4982 - val_acc: 0.8884\n",
      "Epoch 104/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0528 - acc: 0.7092\n",
      "Epoch 00104: val_loss did not improve\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 1.0525 - acc: 0.7094 - val_loss: 0.5159 - val_acc: 0.8587\n",
      "Epoch 105/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.1051 - acc: 0.7018\n",
      "Epoch 00105: val_loss did not improve\n",
      "137/137 [==============================] - 97s 707ms/step - loss: 1.1074 - acc: 0.7014 - val_loss: 0.4694 - val_acc: 0.8768\n",
      "Epoch 106/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.7131\n",
      "Epoch 00106: val_loss did not improve\n",
      "137/137 [==============================] - 100s 731ms/step - loss: 1.0162 - acc: 0.7135 - val_loss: 0.4894 - val_acc: 0.8833\n",
      "Epoch 107/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0264 - acc: 0.7165\n",
      "Epoch 00107: val_loss did not improve\n",
      "137/137 [==============================] - 98s 712ms/step - loss: 1.0285 - acc: 0.7162 - val_loss: 0.4921 - val_acc: 0.8812\n",
      "Epoch 108/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0111 - acc: 0.7213\n",
      "Epoch 00108: val_loss did not improve\n",
      "137/137 [==============================] - 101s 739ms/step - loss: 1.0084 - acc: 0.7218 - val_loss: 0.4510 - val_acc: 0.8870\n",
      "Epoch 109/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0181 - acc: 0.7198\n",
      "Epoch 00109: val_loss did not improve\n",
      "137/137 [==============================] - 97s 709ms/step - loss: 1.0160 - acc: 0.7206 - val_loss: 0.5027 - val_acc: 0.8674\n",
      "Epoch 110/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0182 - acc: 0.7169\n",
      "Epoch 00110: val_loss did not improve\n",
      "137/137 [==============================] - 99s 722ms/step - loss: 1.0215 - acc: 0.7164 - val_loss: 0.5255 - val_acc: 0.8775\n",
      "Epoch 111/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9842 - acc: 0.7258\n",
      "Epoch 00111: val_loss did not improve\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.9840 - acc: 0.7263 - val_loss: 0.4636 - val_acc: 0.8870\n",
      "Epoch 112/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0261 - acc: 0.7251\n",
      "Epoch 00112: val_loss did not improve\n",
      "137/137 [==============================] - 99s 724ms/step - loss: 1.0260 - acc: 0.7248 - val_loss: 0.5041 - val_acc: 0.8703\n",
      "Epoch 113/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0431 - acc: 0.7189\n",
      "Epoch 00113: val_loss did not improve\n",
      "137/137 [==============================] - 97s 704ms/step - loss: 1.0397 - acc: 0.7195 - val_loss: 0.4767 - val_acc: 0.8833\n",
      "Epoch 114/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9587 - acc: 0.7306\n",
      "Epoch 00114: val_loss did not improve\n",
      "137/137 [==============================] - 100s 732ms/step - loss: 0.9577 - acc: 0.7309 - val_loss: 0.5012 - val_acc: 0.8717\n",
      "Epoch 115/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9565 - acc: 0.7388\n",
      "Epoch 00115: val_loss did not improve\n",
      "137/137 [==============================] - 100s 733ms/step - loss: 0.9548 - acc: 0.7385 - val_loss: 0.4731 - val_acc: 0.8804\n",
      "Epoch 116/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9593 - acc: 0.7288\n",
      "Epoch 00116: val_loss did not improve\n",
      "137/137 [==============================] - 97s 710ms/step - loss: 0.9597 - acc: 0.7290 - val_loss: 0.4826 - val_acc: 0.8757\n",
      "Epoch 117/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0132 - acc: 0.7217\n",
      "Epoch 00117: val_loss did not improve\n",
      "137/137 [==============================] - 101s 736ms/step - loss: 1.0113 - acc: 0.7219 - val_loss: 0.4840 - val_acc: 0.8833\n",
      "Epoch 118/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9061 - acc: 0.7466\n",
      "Epoch 00118: val_loss did not improve\n",
      "137/137 [==============================] - 97s 711ms/step - loss: 0.9059 - acc: 0.7467 - val_loss: 0.4801 - val_acc: 0.8790\n",
      "Epoch 119/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9935 - acc: 0.7228\n",
      "Epoch 00119: val_loss did not improve\n",
      "137/137 [==============================] - 100s 728ms/step - loss: 0.9943 - acc: 0.7226 - val_loss: 0.5405 - val_acc: 0.8703\n",
      "Epoch 120/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.7208\n",
      "Epoch 00120: val_loss did not improve\n",
      "137/137 [==============================] - 102s 744ms/step - loss: 1.0158 - acc: 0.7215 - val_loss: 0.5272 - val_acc: 0.8790\n",
      "Epoch 121/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.7297\n",
      "Epoch 00121: val_loss did not improve\n",
      "137/137 [==============================] - 102s 743ms/step - loss: 0.9664 - acc: 0.7308 - val_loss: 0.4562 - val_acc: 0.8746\n",
      "Epoch 122/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0095 - acc: 0.7274\n",
      "Epoch 00122: val_loss did not improve\n",
      "137/137 [==============================] - 98s 716ms/step - loss: 1.0096 - acc: 0.7272 - val_loss: 0.5253 - val_acc: 0.8797\n",
      "Epoch 123/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9898 - acc: 0.7276\n",
      "Epoch 00123: val_loss did not improve\n",
      "137/137 [==============================] - 103s 752ms/step - loss: 0.9886 - acc: 0.7281 - val_loss: 0.4931 - val_acc: 0.8841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8846 - acc: 0.7551\n",
      "Epoch 00124: val_loss did not improve\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.8853 - acc: 0.7550 - val_loss: 0.4834 - val_acc: 0.8783\n",
      "Epoch 125/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9419 - acc: 0.7397\n",
      "Epoch 00125: val_loss did not improve\n",
      "137/137 [==============================] - 98s 719ms/step - loss: 0.9416 - acc: 0.7399 - val_loss: 0.5358 - val_acc: 0.8754\n",
      "Epoch 126/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8626 - acc: 0.7521\n",
      "Epoch 00126: val_loss did not improve\n",
      "137/137 [==============================] - 95s 691ms/step - loss: 0.8599 - acc: 0.7529 - val_loss: 0.4420 - val_acc: 0.8848\n",
      "Epoch 127/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9840 - acc: 0.7323\n",
      "Epoch 00127: val_loss did not improve\n",
      "137/137 [==============================] - 104s 756ms/step - loss: 0.9878 - acc: 0.7312 - val_loss: 0.5085 - val_acc: 0.8790\n",
      "Epoch 128/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0103 - acc: 0.7222\n",
      "Epoch 00128: val_loss did not improve\n",
      "137/137 [==============================] - 97s 707ms/step - loss: 1.0086 - acc: 0.7227 - val_loss: 0.5053 - val_acc: 0.8877\n",
      "Epoch 129/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9736 - acc: 0.7246\n",
      "Epoch 00129: val_loss did not improve\n",
      "137/137 [==============================] - 106s 776ms/step - loss: 0.9710 - acc: 0.7253 - val_loss: 0.4699 - val_acc: 0.8790\n",
      "Epoch 130/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9256 - acc: 0.7408\n",
      "Epoch 00130: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 0.9320 - acc: 0.7399 - val_loss: 0.4801 - val_acc: 0.8775\n",
      "Epoch 131/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0771 - acc: 0.7107\n",
      "Epoch 00131: val_loss did not improve\n",
      "137/137 [==============================] - 105s 764ms/step - loss: 1.0733 - acc: 0.7116 - val_loss: 0.5137 - val_acc: 0.8797\n",
      "Epoch 132/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0090 - acc: 0.7284\n",
      "Epoch 00132: val_loss did not improve\n",
      "137/137 [==============================] - 106s 776ms/step - loss: 1.0060 - acc: 0.7288 - val_loss: 0.5212 - val_acc: 0.8797\n",
      "Epoch 133/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0508 - acc: 0.7235\n",
      "Epoch 00133: val_loss did not improve\n",
      "137/137 [==============================] - 105s 764ms/step - loss: 1.0542 - acc: 0.7225 - val_loss: 0.5011 - val_acc: 0.8783\n",
      "Epoch 134/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0342 - acc: 0.7230\n",
      "Epoch 00134: val_loss did not improve\n",
      "137/137 [==============================] - 105s 763ms/step - loss: 1.0319 - acc: 0.7233 - val_loss: 0.5107 - val_acc: 0.8790\n",
      "Epoch 135/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9363 - acc: 0.7382\n",
      "Epoch 00135: val_loss did not improve\n",
      "137/137 [==============================] - 101s 735ms/step - loss: 0.9335 - acc: 0.7390 - val_loss: 0.5026 - val_acc: 0.8833\n",
      "Epoch 136/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9541 - acc: 0.7354\n",
      "Epoch 00136: val_loss did not improve\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 0.9528 - acc: 0.7355 - val_loss: 0.4847 - val_acc: 0.8841\n",
      "Epoch 137/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 1.0121 - acc: 0.7301\n",
      "Epoch 00137: val_loss did not improve\n",
      "137/137 [==============================] - 101s 737ms/step - loss: 1.0109 - acc: 0.7306 - val_loss: 0.4875 - val_acc: 0.8761\n",
      "Epoch 138/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9067 - acc: 0.7502\n",
      "Epoch 00138: val_loss did not improve\n",
      "137/137 [==============================] - 102s 747ms/step - loss: 0.9113 - acc: 0.7487 - val_loss: 0.5106 - val_acc: 0.8768\n",
      "Epoch 139/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9114 - acc: 0.7461\n",
      "Epoch 00139: val_loss did not improve\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 0.9131 - acc: 0.7458 - val_loss: 0.5032 - val_acc: 0.8800\n",
      "Epoch 140/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9528 - acc: 0.7452\n",
      "Epoch 00140: val_loss did not improve\n",
      "137/137 [==============================] - 102s 745ms/step - loss: 0.9552 - acc: 0.7446 - val_loss: 0.4669 - val_acc: 0.8826\n",
      "Epoch 141/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9430 - acc: 0.7423\n",
      "Epoch 00141: val_loss did not improve\n",
      "137/137 [==============================] - 103s 754ms/step - loss: 0.9467 - acc: 0.7410 - val_loss: 0.5317 - val_acc: 0.8732\n",
      "Epoch 142/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8808 - acc: 0.7550\n",
      "Epoch 00142: val_loss did not improve\n",
      "137/137 [==============================] - 100s 729ms/step - loss: 0.8810 - acc: 0.7550 - val_loss: 0.4849 - val_acc: 0.8855\n",
      "Epoch 143/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9409 - acc: 0.7464\n",
      "Epoch 00143: val_loss did not improve\n",
      "137/137 [==============================] - 102s 741ms/step - loss: 0.9383 - acc: 0.7469 - val_loss: 0.5269 - val_acc: 0.8696\n",
      "Epoch 144/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9954 - acc: 0.7275\n",
      "Epoch 00144: val_loss did not improve\n",
      "137/137 [==============================] - 98s 717ms/step - loss: 0.9922 - acc: 0.7278 - val_loss: 0.4780 - val_acc: 0.8870\n",
      "Epoch 145/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9656 - acc: 0.7375\n",
      "Epoch 00145: val_loss did not improve\n",
      "137/137 [==============================] - 101s 741ms/step - loss: 0.9676 - acc: 0.7365 - val_loss: 0.5254 - val_acc: 0.8710\n",
      "Epoch 146/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.7357\n",
      "Epoch 00146: val_loss did not improve\n",
      "137/137 [==============================] - 97s 711ms/step - loss: 0.9681 - acc: 0.7367 - val_loss: 0.4646 - val_acc: 0.8812\n",
      "Epoch 147/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9436 - acc: 0.7410\n",
      "Epoch 00147: val_loss did not improve\n",
      "137/137 [==============================] - 99s 720ms/step - loss: 0.9409 - acc: 0.7415 - val_loss: 0.4821 - val_acc: 0.8848\n",
      "Epoch 148/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9264 - acc: 0.7456\n",
      "Epoch 00148: val_loss did not improve\n",
      "137/137 [==============================] - 102s 743ms/step - loss: 0.9304 - acc: 0.7451 - val_loss: 0.4928 - val_acc: 0.8877\n",
      "Epoch 149/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9595 - acc: 0.7428\n",
      "Epoch 00149: val_loss did not improve\n",
      "137/137 [==============================] - 100s 734ms/step - loss: 0.9584 - acc: 0.7429 - val_loss: 0.5050 - val_acc: 0.8790\n",
      "Epoch 150/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9198 - acc: 0.7482\n",
      "Epoch 00150: val_loss did not improve\n",
      "137/137 [==============================] - 102s 744ms/step - loss: 0.9187 - acc: 0.7484 - val_loss: 0.4528 - val_acc: 0.8855\n",
      "Epoch 151/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8680 - acc: 0.7534\n",
      "Epoch 00151: val_loss did not improve\n",
      "137/137 [==============================] - 97s 706ms/step - loss: 0.8662 - acc: 0.7541 - val_loss: 0.5455 - val_acc: 0.8725\n",
      "Epoch 152/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9039 - acc: 0.7552\n",
      "Epoch 00152: val_loss did not improve\n",
      "137/137 [==============================] - 97s 707ms/step - loss: 0.9046 - acc: 0.7547 - val_loss: 0.4933 - val_acc: 0.8732\n",
      "Epoch 153/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9382 - acc: 0.7479\n",
      "Epoch 00153: val_loss did not improve\n",
      "137/137 [==============================] - 102s 746ms/step - loss: 0.9370 - acc: 0.7481 - val_loss: 0.4791 - val_acc: 0.8862\n",
      "Epoch 154/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9006 - acc: 0.7572\n",
      "Epoch 00154: val_loss did not improve\n",
      "137/137 [==============================] - 104s 760ms/step - loss: 0.9031 - acc: 0.7562 - val_loss: 0.4650 - val_acc: 0.8804\n",
      "Epoch 155/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8979 - acc: 0.7477\n",
      "Epoch 00155: val_loss did not improve\n",
      "137/137 [==============================] - 100s 733ms/step - loss: 0.9001 - acc: 0.7474 - val_loss: 0.4973 - val_acc: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9076 - acc: 0.7517\n",
      "Epoch 00156: val_loss did not improve\n",
      "137/137 [==============================] - 97s 711ms/step - loss: 0.9062 - acc: 0.7518 - val_loss: 0.4735 - val_acc: 0.8790\n",
      "Epoch 157/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9024 - acc: 0.7574\n",
      "Epoch 00157: val_loss did not improve\n",
      "137/137 [==============================] - 104s 756ms/step - loss: 0.9025 - acc: 0.7570 - val_loss: 0.5313 - val_acc: 0.8797\n",
      "Epoch 158/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9939 - acc: 0.7377\n",
      "Epoch 00158: val_loss did not improve\n",
      "137/137 [==============================] - 101s 736ms/step - loss: 0.9957 - acc: 0.7369 - val_loss: 0.5002 - val_acc: 0.8768\n",
      "Epoch 159/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8454 - acc: 0.7588\n",
      "Epoch 00159: val_loss did not improve\n",
      "137/137 [==============================] - 99s 725ms/step - loss: 0.8436 - acc: 0.7590 - val_loss: 0.4931 - val_acc: 0.8717\n",
      "Epoch 160/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.9415 - acc: 0.7516\n",
      "Epoch 00160: val_loss did not improve\n",
      "137/137 [==============================] - 99s 721ms/step - loss: 0.9385 - acc: 0.7517 - val_loss: 0.4696 - val_acc: 0.8797\n",
      "Epoch 161/5000\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.8649 - acc: 0.7585\n",
      "Epoch 00161: val_loss did not improve\n",
      "137/137 [==============================] - 100s 728ms/step - loss: 0.8622 - acc: 0.7592 - val_loss: 0.4874 - val_acc: 0.8870\n",
      "Epoch 00161: early stopping\n"
     ]
    }
   ],
   "source": [
    "batchSize = 64\n",
    "\n",
    "#if ( not trainFresh ):\n",
    "#    model.load_weights( \"./best/dogClass.hdf5\" )\n",
    "\n",
    "earlyStopper = EarlyStopping( patience = 100, verbose = 1 )\n",
    "checkPointer = ModelCheckpoint( filepath = \"./best/dogClass.hdf5\", save_best_only = True, verbose = 1 )\n",
    "\n",
    "losses = model.fit_generator( genBatch( trainFiles, labels, batchSize, imgSize, True ),\n",
    "                              steps_per_epoch = len(trainFiles) // batchSize,\n",
    "                              validation_data = genBatch( valFiles, labels, batchSize, imgSize, False ),\n",
    "                              validation_steps = len(valFiles) // batchSize,\n",
    "                              epochs = 5000, callbacks = [ earlyStopper, checkPointer ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLosses( losses.history )\n",
    "plotAcc( losses.history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgSize = 256\n",
    "dropout = 0.80\n",
    "\n",
    "model = genModel( imgSize, dropout )\n",
    "model.load_weights(  \"./best/dogClass.hdf5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 120)\n"
     ]
    }
   ],
   "source": [
    "testFiles  = np.array( glob('./testCroped/*.jpg') )\n",
    "\n",
    "def getImage( file, size = 256 ):\n",
    "    \"\"\"Loads a single image with its ID code.\"\"\"\n",
    "\n",
    "    imgID = getImageId( file )\n",
    "    img = image.load_img( file, target_size = (size, size) )\n",
    "    img = image.img_to_array(img)/255\n",
    "\n",
    "    return imgID, img\n",
    "\n",
    "ids = []\n",
    "predictions = []\n",
    "\n",
    "for f in testFiles:\n",
    "    imgID, img = getImage(f)\n",
    "    \n",
    "    pred = model.predict( np.array([img]) )\n",
    "    \n",
    "    ids.append( imgID )\n",
    "    predictions.append( pred[0] )\n",
    "\n",
    "ids = np.array(ids)\n",
    "predictions = np.array( predictions )\n",
    "\n",
    "print( predictions.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.DataFrame( predictions, columns = breeds, index = ids )\n",
    "testData.index.name = \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.to_csv( \"testRes.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
